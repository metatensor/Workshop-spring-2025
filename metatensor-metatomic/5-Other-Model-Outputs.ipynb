{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating models with alternative outputs\n",
    "\n",
    "Models that follow the metatomic interface can have multiple simultaneous outputs. For example, the same model can have an `\"energy\"` output, as well as an `\"energy_uncertainty\"` output, or a `\"features\"` output. \n",
    "\n",
    "There is a set of standardized outputs, which is defined in https://docs.metatensor.org/metatomic/latest/outputs/index.html and growing every day! Models can also use non-standardized outputs by naming as `\"<prefix>::<output>\"`, where `prefix` should indicate the software used to create this output. This allows us to experiment with new outputs outside of metatomic!\n",
    "\n",
    "\n",
    "In this tutorial, we will define a new version of the model from notebook 2, adding a `\"features\"` output that will contain the features at the last layer of the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Optional\n",
    "\n",
    "import ase.io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "torch.manual_seed(123456)\n",
    "\n",
    "from featomic.torch import SoapPowerSpectrum\n",
    "from metatensor.torch import Labels, TensorBlock, TensorMap\n",
    "\n",
    "import metatomic.torch as mta\n",
    "import metatensor.torch as mts\n",
    "\n",
    "from metatomic.torch import System, ModelOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = ase.io.read(\"propenol_conformers_dftb.xyz\", \":500\")\n",
    "\n",
    "energies = np.array([[f.info[\"dftb_energy_eV\"]] for f in frames])\n",
    "forces = np.vstack([f.arrays[\"dftb_forces_eV_per_Ang\"] for f in frames])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add new outputs to a model, we'll need to add another `TensorMap` to the return `dict` of this model.\n",
    "\n",
    "The exact outputs the model should produce are determined by whoever is executing the model; and passed in the `outputs: Dict[str, ModelOutput]` parameter. The code inside the model should thus check this structure to determine whether a given output has been requested, as well as whether this ouptut should be expressed as a per-atom or per-structure.\n",
    "\n",
    "| ![TASK](img/clipboard.png) | Add \"features\" to the result of the model when `per_atom` is False |\n",
    "|----------------------------|--------------------------------------------------------------------|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SOAPModel(torch.nn.Module):\n",
    "    def __init__(self, soap_parameters, atomic_types, energy_offset):\n",
    "        super().__init__()\n",
    "\n",
    "        self.energy_offset = torch.tensor(energy_offset)\n",
    "        self.atomic_types = atomic_types\n",
    "\n",
    "        self.soap_calculator = SoapPowerSpectrum(**soap_parameters)\n",
    "        self.neighbor_atom_types = Labels(\n",
    "            [\"neighbor_1_type\", \"neighbor_2_type\"], \n",
    "            torch.tensor([(i, j) for i in atomic_types for j in atomic_types if i <= j])\n",
    "        )\n",
    "\n",
    "        # Number of features produced by the SOAP calculator,\n",
    "        # i.e. size of the input of the NN\n",
    "        n_soap = (\n",
    "            (soap_parameters[\"basis\"][\"max_angular\"] + 1)\n",
    "            * (soap_parameters[\"basis\"][\"radial\"][\"max_radial\"] + 1) ** 2\n",
    "            * len(self.neighbor_atom_types)\n",
    "        )\n",
    "\n",
    "    \n",
    "        self.nn = mts.learn.nn.ModuleMap(\n",
    "            in_keys = Labels(\"_\", torch.tensor([[0]])),\n",
    "            modules = [torch.nn.Sequential(\n",
    "                torch.nn.Linear(\n",
    "                    in_features=n_soap, out_features=128, bias=False, dtype=torch.float64\n",
    "                ),\n",
    "                torch.nn.SiLU(),\n",
    "                torch.nn.Linear(\n",
    "                    in_features=128, out_features=128, bias=False, dtype=torch.float64\n",
    "                ),\n",
    "                torch.nn.SiLU(),\n",
    "                torch.nn.Linear(\n",
    "                    in_features=128, out_features=5, bias=False, dtype=torch.float64\n",
    "                ),\n",
    "                torch.nn.SiLU(),\n",
    "            )]\n",
    "        )\n",
    "\n",
    "        self.energy_layer = mts.learn.nn.ModuleMap(\n",
    "            in_keys = Labels(\"_\", torch.tensor([[0]])),\n",
    "            modules = [torch.nn.Linear(\n",
    "                in_features=5, out_features=1, bias=True, dtype=torch.float64\n",
    "            )],\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        systems: List[System],\n",
    "        outputs: Dict[str, ModelOutput],\n",
    "        selected_atoms: Optional[Labels] = None,\n",
    "    ) -> Dict[str, TensorMap]:\n",
    "        \n",
    "        soap = self.soap_calculator(systems, selected_samples=selected_atoms)\n",
    "        soap = soap.keys_to_properties(self.neighbor_atom_types)\n",
    "        soap = soap.keys_to_samples(\"center_type\")\n",
    "\n",
    "        nn_features_per_atom = self.nn(soap)\n",
    "        \n",
    "        energies_per_atom = self.energy_layer(nn_features_per_atom)\n",
    "        \n",
    "        energy = mts.sum_over_samples(energies_per_atom, [\"atom\", \"center_type\"])\n",
    "        energy.block().values[:] += self.energy_offset\n",
    "\n",
    "        # add the requested outputs to the results\n",
    "        results: Dict[str, TensorMap] = {}\n",
    "        if \"energy\" in outputs:\n",
    "            results[\"energy\"] = energy\n",
    "\n",
    "        if \"features\" in outputs:\n",
    "            if outputs[\"features\"].per_atom:\n",
    "                results[\"features\"] = nn_features_per_atom\n",
    "            else:\n",
    "                results[\"features\"] =  ...\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now train the model as before, although one difference is that in the training loop we now explicitly request the `\"energy\"` output to be able to create the loss in terms of the energy. \n",
    "\n",
    "Notice how we are **not** training the `\"features\"` output, it is just a derived output that comes from training the model to reproduce the energy of this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOAP_PARAMETERS = {\n",
    "    \"cutoff\": {\n",
    "        \"radius\": 3.5,\n",
    "        \"smoothing\": {\n",
    "            \"type\": \"ShiftedCosine\",\n",
    "            \"width\": 0.2\n",
    "        }\n",
    "    },\n",
    "    \"density\": {\n",
    "        \"type\": \"Gaussian\",\n",
    "        \"width\": 0.3\n",
    "    },\n",
    "    \"basis\": {\n",
    "        \"type\": \"TensorProduct\",\n",
    "        \"max_angular\": 5,\n",
    "        \"radial\": {\n",
    "            \"type\": \"Gto\",\n",
    "            \"max_radial\": 5\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "energy_offset = energies.mean()\n",
    "model = SOAPModel(\n",
    "    SOAP_PARAMETERS,\n",
    "    atomic_types=[1, 6, 8],\n",
    "    energy_offset=energy_offset,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "systems = mta.systems_to_torch(frames, dtype=torch.float64)\n",
    "\n",
    "reference = torch.tensor(energies)\n",
    "mse_loss = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.01)\n",
    "epoch = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = epoch + 1\n",
    "\n",
    "for epoch in range(start, start + 80):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(systems, outputs={\"energy\": ModelOutput(per_atom=False)})\n",
    "\n",
    "    predicted = outputs[\"energy\"].block().values\n",
    "    loss = mse_loss(predicted, reference)\n",
    "\n",
    "    if epoch % 3 == 0:\n",
    "        print(f\"loss at epoch {epoch} is\", loss.item())\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw previously, we can use this model to predict the energy, now explicitly requesting global energies as a model output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_energy = model(systems, {\"energy\": ModelOutput(per_atom=False)})[\"energy\"]\n",
    "\n",
    "plt.scatter(energies, predicted_energy.block().values.detach().numpy())\n",
    "\n",
    "x = [np.min(energies), np.max(energies)]\n",
    "plt.plot(x, x, c=\"grey\")\n",
    "\n",
    "plt.title(\"energies\")\n",
    "plt.xlabel(\"reference / eV\")\n",
    "plt.ylabel(\"predicted / eV\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| ![TASK](img/clipboard.png) | Run the model and extract the `\"features\"` output with `per_atom=False` |\n",
    "|----------------------------|-------------------------------------------------------------------------|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ...\n",
    "\n",
    "features = features.block().values.detach().numpy()\n",
    "if features.shape != (len(systems), 5):\n",
    "    raise Exception(\"wrong output from the model\")\n",
    "\n",
    "plt.scatter(features[:, 0], features[:, 1])\n",
    "\n",
    "plt.title(\"features\")\n",
    "plt.xlabel(\"NN feature 1\")\n",
    "plt.ylabel(\"NN feature 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting the model\n",
    "\n",
    "We can export the model as we did previously, making sure to declare the two possible outputs in the model's capabilities.\n",
    "\n",
    "One difference from the model in notebook 2 is that we now directly return a `Dict[str, TensorMap]`, so we don't need to define an additional `ExportWrapper` class. In essence, notebook 2 is how it would look like to wrap existing code to make it compatible with metatomic, while this notebook shows an example of directly defining a metatomic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metatomic.torch import (\n",
    "    AtomisticModel, \n",
    "    System, \n",
    "    ModelOutput, \n",
    "    ModelMetadata, \n",
    "    ModelCapabilities, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we now have two outputs:\n",
    "energy_output = ModelOutput(\n",
    "    quantity=\"energy\",\n",
    "    unit=\"eV\",\n",
    "    per_atom=False,\n",
    ")\n",
    "\n",
    "features_output = ModelOutput(\n",
    "    quantity=\"\",\n",
    "    per_atom=True,\n",
    ")\n",
    "\n",
    "capabilities = ModelCapabilities(\n",
    "    length_unit=\"angstrom\",\n",
    "    interaction_range=SOAP_PARAMETERS[\"cutoff\"][\"radius\"],\n",
    "    atomic_types=[1, 6, 8],\n",
    "    supported_devices=[\"cpu\"],\n",
    "    dtype = \"float64\",\n",
    "    # define the two outputs\n",
    "    outputs={\n",
    "        \"energy\": energy_output,\n",
    "        \"features\": features_output,\n",
    "    },\n",
    ")\n",
    "\n",
    "metadata = ModelMetadata(\n",
    "    name=\"A simple SOAP NN model\",\n",
    "    description=\"...\",\n",
    "    authors=[],\n",
    "    references={}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metatensor_model = AtomisticModel(model.eval(), metadata, capabilities)\n",
    "metatensor_model.save(\"model-with-features.pt\", collect_extensions=\"extensions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the `\"features\"` output\n",
    "\n",
    "This new output of our model can currently be used by two simulation tools: chemiscope and PLUMED. In PLUMED, the `\"features\"` output can be used to define custom collective variables for enhanced sampling. See the documentation here for more information: https://docs.metatensor.org/metatomic/latest/engines/plumed.html\n",
    "\n",
    "In [chemiscope](https://chemiscope.org), the `\"features\"` output can be used together with `chemiscope.explore` to automatically extract relevant features from a dataset. You can find the corresponding documentation here: https://chemiscope.org/docs/examples/6-explore.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chemiscope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to create a `featurizer` function, and chemiscope provides the `metatomic_featurizer` function to automatically convert a metatomic model into a featurizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurizer = chemiscope.metatomic_featurizer(model=\"model-with-features.pt\", extensions_directory=\"extensions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use this featurizer with a dataset (here the full propenol dataset) to see how different structures are seen by the model, and how different structures are mapped to different points in the abstract feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "propenol = ase.io.read(\"propenol_conformers_dftb.xyz\", \":\")\n",
    "\n",
    "chemiscope.explore(propenol, featurizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the same featurizer with a completely different dataset, as long as the atomic types of the dataset are supported by the model. Here for example we can load a dataset of ethanol molecules and visualize the features in the same way!\n",
    "\n",
    "**HINT:** you can change the features you visualize by clicking on the â˜° icon on the top left!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ethanol = ase.io.read(\"ethanol.xyz\", \":\")\n",
    "chemiscope.explore(ethanol, featurizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because our model supports `per_atom` features as well, chemiscope can use it to compute the features associated with different atoms in the molecules! The way to do this is to set the `environments` parameter to the list of atom-centered environments of interest. `all_atomic_environments` will set this to all possible atomic environments in the structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemiscope.explore(ethanol, featurizer, environments=chemiscope.all_atomic_environments(ethanol))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
